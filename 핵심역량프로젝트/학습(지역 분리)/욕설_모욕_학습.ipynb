{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "욕설_모욕\n",
       "0    332\n",
       "1     34\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir('C:/Users/USER/Desktop/핵심역량 프로젝트/데이터/라벨링 데이터')\n",
    "\n",
    "data1 = pd.read_csv('0726_masking_labeling_data_0.csv')\n",
    "data2 = pd.read_csv('0726_masking_labeling_data_1.csv')\n",
    "\n",
    "\n",
    "selected_columns1 = ['text_morphed', 'aggr', '욕설_모욕', '비꼼_시비', '성희롱', '요지불명', '저격성 민원']\n",
    "data1 = data1[selected_columns1]\n",
    "data2 = data2[selected_columns1]\n",
    "\n",
    "data2['욕설_모욕'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['저격성민원_'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training extra_trees...\n",
      "extra_trees - X_train shape: (320, 7417)\n",
      "extra_trees - X_test shape: (80, 7417)\n",
      "extra_trees Train set score: 1.0000\n",
      "extra_trees Test set score: 0.9125\n",
      "extra_trees Cross-validation scores: [0.90625  0.90625  0.921875 0.921875 0.921875]\n",
      "extra_trees Cross-validation mean score: 0.9156\n",
      "\n",
      "Training ridge_classifier...\n",
      "ridge_classifier - X_train shape: (320, 7417)\n",
      "ridge_classifier - X_test shape: (80, 7417)\n",
      "ridge_classifier Train set score: 0.9938\n",
      "ridge_classifier Test set score: 0.9125\n",
      "ridge_classifier Cross-validation scores: [0.90625  0.90625  0.921875 0.921875 0.921875]\n",
      "ridge_classifier Cross-validation mean score: 0.9156\n",
      "\n",
      "Training logistic_regression...\n",
      "logistic_regression - X_train shape: (320, 7417)\n",
      "logistic_regression - X_test shape: (80, 7417)\n",
      "logistic_regression Train set score: 0.9156\n",
      "logistic_regression Test set score: 0.9125\n",
      "logistic_regression Cross-validation scores: [0.90625  0.90625  0.921875 0.921875 0.921875]\n",
      "logistic_regression Cross-validation mean score: 0.9156\n",
      "\n",
      "Training naive_bayes...\n",
      "naive_bayes - X_train shape: (320, 7417)\n",
      "naive_bayes - X_test shape: (80, 7417)\n",
      "naive_bayes Train set score: 0.9156\n",
      "naive_bayes Test set score: 0.9125\n",
      "naive_bayes Cross-validation scores: [0.90625  0.90625  0.921875 0.921875 0.921875]\n",
      "naive_bayes Cross-validation mean score: 0.9156\n",
      "\n",
      "Training svm...\n",
      "svm - X_train shape: (320, 7417)\n",
      "svm - X_test shape: (80, 7417)\n",
      "svm Train set score: 0.9594\n",
      "svm Test set score: 0.9125\n",
      "svm Cross-validation scores: [0.90625  0.90625  0.921875 0.921875 0.921875]\n",
      "svm Cross-validation mean score: 0.9156\n",
      "\n",
      "Training hard_model...\n",
      "hard_model - X_train shape: (320, 7417)\n",
      "hard_model - X_test shape: (80, 7417)\n",
      "hard_model Train set score: 0.9594\n",
      "hard_model Test set score: 0.9125\n",
      "hard_model Cross-validation scores: [0.90625  0.90625  0.921875 0.921875 0.921875]\n",
      "hard_model Cross-validation mean score: 0.9156\n",
      "\n",
      "Training soft_model...\n",
      "soft_model - X_train shape: (320, 7417)\n",
      "soft_model - X_test shape: (80, 7417)\n",
      "soft_model Train set score: 1.0000\n",
      "soft_model Test set score: 0.9125\n",
      "soft_model Cross-validation scores: [0.90625  0.90625  0.921875 0.921875 0.921875]\n",
      "soft_model Cross-validation mean score: 0.9156\n",
      "\n",
      "All models have been trained and saved.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib\n",
    "\n",
    "# 데이터 불러오기\n",
    "os.chdir('C:/Users/USER/Desktop/핵심역량 프로젝트/데이터/라벨링 데이터')\n",
    "\n",
    "data1 = pd.read_csv('0726_masking_labeling_data_0.csv')\n",
    "data2 = pd.read_csv('0726_masking_labeling_data_1.csv')\n",
    "\n",
    "data1 = data1.rename(columns={'text_morphed':'text_morphed_'})\n",
    "data2 = data2.rename(columns={'text_morphed':'text_morphed_'})\n",
    "\n",
    "\n",
    "selected_columns1 = ['title','text_morphed_', 'aggr', '욕설_모욕', '비꼼_시비', '성희롱', '요지불명', '저격성 민원']\n",
    "\n",
    "target = selected_columns1[2]\n",
    "\n",
    "data1 = data1[selected_columns1]\n",
    "data2 = data2[selected_columns1]\n",
    "data1 = data1[300:334]                    #라벨 데이터 개수만큼 설정\n",
    "data2 = data2[data2[target] == 1]   #라벨 컬럼 설정\n",
    "\n",
    "data3 = pd.concat([data1, data2])\n",
    "# 텍스트와 라벨 분리\n",
    "data_contents = data3['text_morphed_'] + ' ' + data3['title']\n",
    "data_labeling = data3[f'{target}']    #라벨 컬럼 설정\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_contents, data_labeling, stratify=data_labeling, test_size=0.2,)\n",
    "\n",
    "# 파이프라인 정의\n",
    "pipelines = {\n",
    "\n",
    "    'extra_trees': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('et', ExtraTreesClassifier())\n",
    "    ]),\n",
    "\n",
    "    'ridge_classifier': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('ridge', RidgeClassifier())\n",
    "    ]),\n",
    "\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('lr', LogisticRegression())\n",
    "    ]),\n",
    "\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('nb', MultinomialNB())\n",
    "    ]),\n",
    "\n",
    "    'svm': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('svm', SVC())\n",
    "    ]),\n",
    "\n",
    "\n",
    "    'hard_model' : Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('hard_model',VotingClassifier([('LR',LogisticRegression()),('ridge',RidgeClassifier()),('svm',SVC()),('et',ExtraTreesClassifier()),('nb',MultinomialNB())],voting='hard'))\n",
    "\n",
    "    ]),\n",
    "    'soft_model' : Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('soft_model',VotingClassifier([('LR',LogisticRegression()),('svm',SVC(probability=True)),('et',ExtraTreesClassifier()),('nb',MultinomialNB())],voting='soft'))\n",
    "\n",
    "    ])\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "# 모델 훈련 및 평가\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # 텍스트 데이터를 TF-IDF 벡터로 변환\n",
    "    X_train_tfidf = pipeline.named_steps['vect'].fit_transform(X_train)\n",
    "    X_test_tfidf = pipeline.named_steps['vect'].transform(X_test)\n",
    "    \n",
    "    # 차원 출력\n",
    "    print(f\"{model_name} - X_train shape: {X_train_tfidf.shape}\")\n",
    "    print(f\"{model_name} - X_test shape: {X_test_tfidf.shape}\")\n",
    "    \n",
    "    # 모델 훈련\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # 교차검증 점수 계산\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # 성능 출력\n",
    "    train_score = pipeline.score(X_train, y_train)\n",
    "    test_score = pipeline.score(X_test, y_test)\n",
    "    print(f\"{model_name} Train set score: {train_score:.4f}\")\n",
    "    print(f\"{model_name} Test set score: {test_score:.4f}\")\n",
    "    print(f\"{model_name} Cross-validation scores: {cv_scores}\")\n",
    "    print(f\"{model_name} Cross-validation mean score: {cv_scores.mean():.4f}\\n\")\n",
    "    \n",
    "    # 모델 저장\n",
    "    model_save_path = os.path.join('C:/Users/USER/Desktop/핵심역량 프로젝트/데이터/모델/', f'{target}_{model_name}_tfidf_nonemasking_model.pkl')\n",
    "    joblib.dump(pipeline, model_save_path)\n",
    "\n",
    "print(\"All models have been trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_morphed_masked_</th>\n",
       "      <th>aggr</th>\n",
       "      <th>욕설_모욕</th>\n",
       "      <th>비꼼_시비</th>\n",
       "      <th>성희롱</th>\n",
       "      <th>요지불명</th>\n",
       "      <th>저격성민원_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>저번 국민 신문고 광산경찰서 올리 접수 이첩 하 기억 날 다시 `지역` 경찰서 올리...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>`지역` `지역` 피버노바 고시원 난장이 목수 놈 주제 재판 변호사비 날리 ㄱ ㅡ ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>얼마 전 차량 운행 라지에 터 파열 되 노상 정차 일 생기 `지역` 주황색 점선 도...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>안녕 하 우선 간접흡연 인하 `지역` 나쁘 두서 없 죄송 무슨 부산대역 근방 전체 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>`지역` `지역` 세대 에스 아파트 아파트 관리실 약 전 바로 옆 구 아 촌 건물 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>`지역` 청 담당자 아래 같이 지나 민원 시작 부 분명히 각자 민원인 제기 의견 다...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>귀 의심 어떻하 고등학교 앞 세대 아파트 옆 높이 철탑 세우 밤낮없이 공치 소리 날...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>도데체 무슨 생각 허가 하 한심 진짜 주말 새벽 골프 공 소리 땅땅 하 들리 잠 깨...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>골프장 짓 지금 포크레인 땅 헤집 난리 발굴 조사 바로 몇 미터 옆 친환경 생태 사...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>`지역` 암암리 `지역` 바로 위 기괴 철탑 거대 하 공용 야외 골프장 허기 하 하...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>얼마 전 심야 버스 정시 출발 안 하 문제 민원 제기 하 사람 그런데 그 후 일인 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>어떤 돌대가리 내 아이디어 모르 그 한 놈 제주시 민이 빅 엿 먹 신음 순실 병신 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>쓰레기 집착하 고시 장님 미치 요일 배출 문제 배출 시간 자정 이후 새벽 요일 불명...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>치킨 집 하 쓰레기 요일 음식점 하 사람 어떻하 음식점 안 쓰레기 가득 차 쓰레기통...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>제주시청 민원 목록 번호 황금 어장 위생 및 친절 제주시청 민원 목록 번호 황금 어...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>오후 일어나 일 다름 우연히 교차로 신문 보 장제비 지급 대하 내용 있 궁금하 국민...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>단오 문화관 이용 시민 장애인 화장실 실태 대하 `지역` 단오 문화관 장애인 화장 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>오늘 시청 일 있 점심 시간 걸리 조금 안되 식당 용 코 엘리베이터 타 일층 공무원...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>군수 군 살림 꾸리 수고 많 덕분 부여군 민이 자부심 생활 힘 되 건의 드릴 군수 ...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>진짜 무슨 연꽃 축제 하 진짜 쳐다보 싫 진짜 완전 짜증나 죽 진짜 이맘때 되 짜증...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>이제 영농기 농작물 피해 주 고라니 너구리 족제비 까치 꿩 기타 이런 유해 야생동물...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  text_morphed_masked_  aggr  욕설_모욕  비꼼_시비  \\\n",
       "14   저번 국민 신문고 광산경찰서 올리 접수 이첩 하 기억 날 다시 `지역` 경찰서 올리...     1      1      1   \n",
       "20   `지역` `지역` 피버노바 고시원 난장이 목수 놈 주제 재판 변호사비 날리 ㄱ ㅡ ...     1      1      1   \n",
       "28   얼마 전 차량 운행 라지에 터 파열 되 노상 정차 일 생기 `지역` 주황색 점선 도...     1      1      1   \n",
       "35   안녕 하 우선 간접흡연 인하 `지역` 나쁘 두서 없 죄송 무슨 부산대역 근방 전체 ...     1      1      1   \n",
       "44   `지역` `지역` 세대 에스 아파트 아파트 관리실 약 전 바로 옆 구 아 촌 건물 ...     1      1      1   \n",
       "85   `지역` 청 담당자 아래 같이 지나 민원 시작 부 분명히 각자 민원인 제기 의견 다...     1      1      1   \n",
       "89   귀 의심 어떻하 고등학교 앞 세대 아파트 옆 높이 철탑 세우 밤낮없이 공치 소리 날...     1      1      1   \n",
       "90   도데체 무슨 생각 허가 하 한심 진짜 주말 새벽 골프 공 소리 땅땅 하 들리 잠 깨...     1      1      1   \n",
       "93   골프장 짓 지금 포크레인 땅 헤집 난리 발굴 조사 바로 몇 미터 옆 친환경 생태 사...     1      1      1   \n",
       "94   `지역` 암암리 `지역` 바로 위 기괴 철탑 거대 하 공용 야외 골프장 허기 하 하...     1      1      1   \n",
       "102  얼마 전 심야 버스 정시 출발 안 하 문제 민원 제기 하 사람 그런데 그 후 일인 ...     1      1      1   \n",
       "104  어떤 돌대가리 내 아이디어 모르 그 한 놈 제주시 민이 빅 엿 먹 신음 순실 병신 ...     1      1      0   \n",
       "105  쓰레기 집착하 고시 장님 미치 요일 배출 문제 배출 시간 자정 이후 새벽 요일 불명...     1      1      0   \n",
       "106  치킨 집 하 쓰레기 요일 음식점 하 사람 어떻하 음식점 안 쓰레기 가득 차 쓰레기통...     1      1      1   \n",
       "114  제주시청 민원 목록 번호 황금 어장 위생 및 친절 제주시청 민원 목록 번호 황금 어...     1      1      0   \n",
       "133  오후 일어나 일 다름 우연히 교차로 신문 보 장제비 지급 대하 내용 있 궁금하 국민...     1      1      0   \n",
       "158  단오 문화관 이용 시민 장애인 화장실 실태 대하 `지역` 단오 문화관 장애인 화장 ...     1      1      0   \n",
       "167  오늘 시청 일 있 점심 시간 걸리 조금 안되 식당 용 코 엘리베이터 타 일층 공무원...     1      1      1   \n",
       "177  군수 군 살림 꾸리 수고 많 덕분 부여군 민이 자부심 생활 힘 되 건의 드릴 군수 ...     1      1      1   \n",
       "178  진짜 무슨 연꽃 축제 하 진짜 쳐다보 싫 진짜 완전 짜증나 죽 진짜 이맘때 되 짜증...     1      1      0   \n",
       "191  이제 영농기 농작물 피해 주 고라니 너구리 족제비 까치 꿩 기타 이런 유해 야생동물...     1      1      0   \n",
       "\n",
       "     성희롱  요지불명  저격성민원_  \n",
       "14     0     1       0  \n",
       "20     0     1       0  \n",
       "28     0     0       0  \n",
       "35     0     0       0  \n",
       "44     0     0       0  \n",
       "85     0     0       0  \n",
       "89     0     0       0  \n",
       "90     0     0       0  \n",
       "93     0     0       0  \n",
       "94     0     0       0  \n",
       "102    0     0       0  \n",
       "104    0     0       0  \n",
       "105    0     0       1  \n",
       "106    0     0       0  \n",
       "114    0     0       0  \n",
       "133    0     0       1  \n",
       "158    0     0       0  \n",
       "167    0     0       0  \n",
       "177    0     0       1  \n",
       "178    0     0       0  \n",
       "191    0     0       0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns1 = ['text_morphed_masked_', 'aggr', '욕설_모욕', '비꼼_시비', '성희롱', '요지불명', '저격성민원_']\n",
    "data1 = data1[selected_columns1]\n",
    "data2 = data2[selected_columns1]\n",
    "data1 = data1[:22]\n",
    "data2 = data2[data2.욕설_모욕 == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 데이터 병합\n",
    "data3 = pd.concat([data1, data2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "욕설_모욕\n",
       "0    374\n",
       "1     21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data3['욕설_모욕'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "욕설_모욕\n",
       "0    176\n",
       "1     21\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2['욕설_모욕'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training logistic_regression...\n",
      "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\", line 237, in fit_transform\n",
      "    raise ValueError(\n",
      "ValueError: n_components(1000) must be <= n_features(785).\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.61616162 0.61616162 0.61616162 0.61616162 0.61616162 0.61616162\n",
      "        nan        nan        nan 0.55555556 0.55555556 0.55555556\n",
      " 0.55555556 0.55555556 0.55555556        nan        nan        nan\n",
      " 0.82828283 0.82828283 0.82828283 0.82828283 0.82828283 0.82828283\n",
      "        nan        nan        nan 0.67424242 0.67424242 0.67424242\n",
      " 0.67424242 0.67424242 0.67424242        nan        nan        nan\n",
      " 0.73989899 0.73989899 0.73989899 0.73989899 0.73989899 0.73989899\n",
      "        nan        nan        nan 0.67171717 0.67171717 0.67171717\n",
      " 0.67171717 0.67171717 0.67171717        nan        nan        nan\n",
      " 0.79292929 0.79292929 0.79292929 0.79292929 0.79292929 0.79292929\n",
      "        nan        nan        nan 0.64393939 0.64393939 0.64393939\n",
      " 0.64393939 0.64393939 0.64393939        nan        nan        nan\n",
      " 0.76262626 0.76262626 0.76262626 0.76262626 0.76262626 0.76262626\n",
      "        nan        nan        nan 0.67424242 0.67424242 0.67424242\n",
      " 0.67424242 0.67424242 0.67424242        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "logistic_regression Best parameters found: {'lr__C': 0.01, 'lr__solver': 'liblinear', 'pca__n_components': 100, 'vect__max_features': 10000}\n",
      "logistic_regression Best cross-validation score: 0.8283\n",
      "logistic_regression Test set score: 0.6667\n",
      "\n",
      "Training svm...\n",
      "Fitting 3 folds for each of 90 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "30 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\", line 237, in fit_transform\n",
      "    raise ValueError(\n",
      "ValueError: n_components(1000) must be <= n_features(785).\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.49747475 0.49747475 0.49747475 0.52525253 0.52525253 0.52525253\n",
      " 0.58333333 0.58333333 0.58333333 0.52525253 0.52525253 0.52525253\n",
      " 0.70454545 0.70454545 0.70454545 0.52525253 0.52525253 0.52525253\n",
      " 0.70454545 0.70454545 0.70454545 0.55555556 0.55555556 0.55555556\n",
      " 0.70454545 0.70454545 0.70454545 0.61363636 0.61363636 0.61363636\n",
      " 0.49747475 0.49747475 0.49747475 0.52525253 0.52525253 0.52525253\n",
      " 0.58333333 0.58333333 0.58333333 0.52525253 0.52525253 0.52525253\n",
      " 0.70454545 0.70454545 0.70454545 0.52525253 0.52525253 0.52525253\n",
      " 0.70454545 0.70454545 0.70454545 0.55555556 0.55555556 0.55555556\n",
      " 0.70454545 0.70454545 0.70454545 0.61363636 0.61363636 0.61363636\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "svm Best parameters found: {'pca__n_components': 100, 'svm__C': 0.1, 'svm__kernel': 'linear', 'vect__max_features': 10000}\n",
      "svm Best cross-validation score: 0.7045\n",
      "svm Test set score: 0.5556\n",
      "\n",
      "Training random_forest...\n",
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "36 fits failed out of a total of 324.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "36 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\", line 237, in fit_transform\n",
      "    raise ValueError(\n",
      "ValueError: n_components(1000) must be <= n_features(785).\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.67424242 0.66919192 0.58333333 0.64646465 0.61363636 0.72727273\n",
      " 0.67171717 0.61616162 0.58585859 0.61616162 0.58585859 0.64393939\n",
      " 0.67424242 0.7020202  0.61363636 0.58585859 0.61616162 0.67424242\n",
      " 0.61616162 0.70454545 0.7020202  0.64393939 0.67424242 0.61363636\n",
      " 0.67424242 0.61616162 0.67171717 0.69949495 0.61363636 0.67171717\n",
      " 0.64393939 0.58585859 0.58838384 0.72979798 0.64646465 0.64646465\n",
      " 0.7020202  0.67171717 0.64393939 0.61616162 0.72979798 0.61616162\n",
      " 0.61616162 0.67171717 0.67171717 0.61616162 0.58838384 0.61363636\n",
      " 0.64393939 0.7020202  0.67171717 0.67424242 0.64141414 0.7020202\n",
      " 0.61363636 0.55808081 0.58585859 0.61616162 0.67171717 0.61616162\n",
      " 0.64393939 0.67424242 0.67171717 0.64393939 0.67171717 0.61616162\n",
      " 0.67171717 0.61363636 0.58333333 0.67424242 0.64646465 0.67171717\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "random_forest Best parameters found: {'pca__n_components': 100, 'rf__max_depth': 30, 'rf__n_estimators': 200, 'vect__max_features': 10000}\n",
      "random_forest Best cross-validation score: 0.7298\n",
      "random_forest Test set score: 0.7778\n",
      "\n",
      "Training gradient_boosting...\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "81 fits failed out of a total of 729.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "81 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\", line 237, in fit_transform\n",
      "    raise ValueError(\n",
      "ValueError: n_components(1000) must be <= n_features(785).\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.52777778 0.49747475 0.52525253 0.55555556 0.55555556 0.5530303\n",
      "        nan        nan        nan 0.52525253 0.52777778 0.49747475\n",
      " 0.55555556 0.55555556 0.58333333        nan        nan        nan\n",
      " 0.5530303  0.49747475 0.52777778 0.55555556 0.5530303  0.5530303\n",
      "        nan        nan        nan 0.5530303  0.5530303  0.61363636\n",
      " 0.52525253 0.58585859 0.52525253        nan        nan        nan\n",
      " 0.64393939 0.52777778 0.58585859 0.52525253 0.64393939 0.52525253\n",
      "        nan        nan        nan 0.52777778 0.58838384 0.49747475\n",
      " 0.55808081 0.49747475 0.52525253        nan        nan        nan\n",
      " 0.55808081 0.5530303  0.49747475 0.5530303  0.55808081 0.55555556\n",
      "        nan        nan        nan 0.55555556 0.52777778 0.55808081\n",
      " 0.55808081 0.52777778 0.52525253        nan        nan        nan\n",
      " 0.61616162 0.55555556 0.55555556 0.55808081 0.58838384 0.52525253\n",
      "        nan        nan        nan 0.58838384 0.5530303  0.5530303\n",
      " 0.64393939 0.64393939 0.58838384        nan        nan        nan\n",
      " 0.49747475 0.5530303  0.58333333 0.55555556 0.64393939 0.58585859\n",
      "        nan        nan        nan 0.61616162 0.58838384 0.61363636\n",
      " 0.52777778 0.55555556 0.55808081        nan        nan        nan\n",
      " 0.58838384 0.58333333 0.61363636 0.49747475 0.61616162 0.64393939\n",
      "        nan        nan        nan 0.55808081 0.5530303  0.61616162\n",
      " 0.52777778 0.64393939 0.52525253        nan        nan        nan\n",
      " 0.55555556 0.61616162 0.61363636 0.55555556 0.61616162 0.49747475\n",
      "        nan        nan        nan 0.52777778 0.5530303  0.52777778\n",
      " 0.55555556 0.58333333 0.58333333        nan        nan        nan\n",
      " 0.61363636 0.58333333 0.49747475 0.61616162 0.58333333 0.52525253\n",
      "        nan        nan        nan 0.58585859 0.55808081 0.52525253\n",
      " 0.58585859 0.61363636 0.52525253        nan        nan        nan\n",
      " 0.58838384 0.61616162 0.58585859 0.58585859 0.5530303  0.61616162\n",
      "        nan        nan        nan 0.5530303  0.64393939 0.55808081\n",
      " 0.61363636 0.5530303  0.58333333        nan        nan        nan\n",
      " 0.55555556 0.55555556 0.61363636 0.55555556 0.64393939 0.61363636\n",
      "        nan        nan        nan 0.52777778 0.52777778 0.55808081\n",
      " 0.58585859 0.49747475 0.58838384        nan        nan        nan\n",
      " 0.5530303  0.58838384 0.58585859 0.64393939 0.58333333 0.52525253\n",
      "        nan        nan        nan 0.58585859 0.61363636 0.58333333\n",
      " 0.55555556 0.52525253 0.5530303         nan        nan        nan\n",
      " 0.61616162 0.64393939 0.55808081 0.61616162 0.61363636 0.61363636\n",
      "        nan        nan        nan 0.5530303  0.64393939 0.5530303\n",
      " 0.61616162 0.58333333 0.55808081        nan        nan        nan\n",
      " 0.52777778 0.64393939 0.5530303  0.58333333 0.64393939 0.64393939\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "gradient_boosting Best parameters found: {'gb__learning_rate': 0.01, 'gb__max_depth': 5, 'gb__n_estimators': 100, 'pca__n_components': 100, 'vect__max_features': 10000}\n",
      "gradient_boosting Best cross-validation score: 0.6439\n",
      "gradient_boosting Test set score: 0.7778\n",
      "\n",
      "Training ada_boost...\n",
      "Fitting 3 folds for each of 81 candidates, totalling 243 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "27 fits failed out of a total of 243.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\", line 237, in fit_transform\n",
      "    raise ValueError(\n",
      "ValueError: n_components(1000) must be <= n_features(785).\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.53030303 0.53030303 0.53030303 0.53030303 0.53030303 0.53030303\n",
      "        nan        nan        nan 0.58585859 0.58585859 0.58585859\n",
      " 0.58585859 0.58585859 0.58585859        nan        nan        nan\n",
      " 0.58585859 0.58585859 0.58585859 0.58585859 0.58585859 0.58585859\n",
      "        nan        nan        nan 0.64646465 0.64646465 0.64646465\n",
      " 0.64646465 0.64646465 0.64646465        nan        nan        nan\n",
      " 0.67676768 0.67676768 0.67676768 0.67676768 0.67676768 0.67676768\n",
      "        nan        nan        nan 0.61616162 0.61616162 0.61616162\n",
      " 0.61616162 0.61616162 0.61616162        nan        nan        nan\n",
      " 0.64646465 0.64646465 0.64646465 0.64646465 0.64646465 0.64646465\n",
      "        nan        nan        nan 0.56060606 0.56060606 0.56060606\n",
      " 0.56060606 0.56060606 0.56060606        nan        nan        nan\n",
      " 0.61616162 0.61616162 0.61616162 0.61616162 0.61616162 0.61616162\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ada_boost Best parameters found: {'ada__learning_rate': 0.01, 'ada__n_estimators': 100, 'pca__n_components': 100, 'vect__max_features': 10000}\n",
      "ada_boost Best cross-validation score: 0.6768\n",
      "ada_boost Test set score: 0.8889\n",
      "\n",
      "Training xgboost...\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "81 fits failed out of a total of 729.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "81 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\", line 237, in fit_transform\n",
      "    raise ValueError(\n",
      "ValueError: n_components(1000) must be <= n_features(785).\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.55808081 0.55808081 0.55555556 0.55808081 0.55808081 0.55555556\n",
      " 0.55808081 0.55808081 0.55555556 0.52777778 0.55808081 0.55808081\n",
      " 0.52777778 0.55808081 0.55808081 0.52777778 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081 0.55555556\n",
      " 0.55808081 0.55808081 0.55555556 0.55808081 0.55808081 0.55555556\n",
      " 0.52777778 0.55808081 0.55808081 0.52777778 0.55808081 0.55808081\n",
      " 0.52777778 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55555556 0.55808081 0.55808081 0.55555556\n",
      " 0.55808081 0.55808081 0.55555556 0.52777778 0.55808081 0.55808081\n",
      " 0.52777778 0.55808081 0.55808081 0.52777778 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081 0.55555556\n",
      " 0.55808081 0.55808081 0.55555556 0.55808081 0.55808081 0.55555556\n",
      " 0.52777778 0.55808081 0.55808081 0.52777778 0.55808081 0.55808081\n",
      " 0.52777778 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55555556 0.55808081 0.55808081 0.55555556\n",
      " 0.55808081 0.55808081 0.55555556 0.52777778 0.55808081 0.55808081\n",
      " 0.52777778 0.55808081 0.55808081 0.52777778 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081 0.55555556\n",
      " 0.55808081 0.55808081 0.55555556 0.55808081 0.55808081 0.55555556\n",
      " 0.52777778 0.55808081 0.55808081 0.52777778 0.55808081 0.55808081\n",
      " 0.52777778 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081\n",
      " 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081 0.55808081\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "xgboost Best parameters found: {'pca__n_components': 100, 'vect__max_features': 10000, 'xgb__learning_rate': 0.01, 'xgb__max_depth': 3, 'xgb__n_estimators': 50}\n",
      "xgboost Best cross-validation score: 0.5581\n",
      "xgboost Test set score: 0.6667\n",
      "\n",
      "Training lightgbm...\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "81 fits failed out of a total of 729.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "81 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\", line 237, in fit_transform\n",
      "    raise ValueError(\n",
      "ValueError: n_components(1000) must be <= n_features(785).\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan 0.46969697 0.46969697 0.46969697\n",
      " 0.46969697 0.46969697 0.46969697        nan        nan        nan\n",
      " 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697 0.46969697\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 17, number of negative: 17\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 34, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "\n",
      "lightgbm Best parameters found: {'lgb__learning_rate': 0.01, 'lgb__max_depth': 3, 'lgb__n_estimators': 50, 'pca__n_components': 100, 'vect__max_features': 10000}\n",
      "lightgbm Best cross-validation score: 0.4697\n",
      "lightgbm Test set score: 0.5556\n",
      "\n",
      "Training catboost...\n",
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n",
      "\n",
      "catboost Best parameters found: {'cat__depth': 5, 'cat__iterations': 50, 'cat__learning_rate': 0.1, 'pca__n_components': 100, 'vect__max_features': 10000}\n",
      "catboost Best cross-validation score: 0.7045\n",
      "catboost Test set score: 0.3333\n",
      "\n",
      "All models have been trained and saved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "81 fits failed out of a total of 729.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "81 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "                            ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\decomposition\\_truncated_svd.py\", line 237, in fit_transform\n",
      "    raise ValueError(\n",
      "ValueError: n_components(1000) must be <= n_features(785).\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\USER\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.64393939 0.64393939 0.64393939 0.64393939 0.64393939 0.64393939\n",
      "        nan        nan        nan 0.64646465 0.64646465 0.64646465\n",
      " 0.64646465 0.64646465 0.64646465        nan        nan        nan\n",
      " 0.58585859 0.58585859 0.58585859 0.58585859 0.58585859 0.58585859\n",
      "        nan        nan        nan 0.67171717 0.67171717 0.67171717\n",
      " 0.67171717 0.67171717 0.67171717        nan        nan        nan\n",
      " 0.64393939 0.64393939 0.64393939 0.64393939 0.64393939 0.64393939\n",
      "        nan        nan        nan 0.61363636 0.61363636 0.61363636\n",
      " 0.61363636 0.61363636 0.61363636        nan        nan        nan\n",
      " 0.67424242 0.67424242 0.67424242 0.67424242 0.67424242 0.67424242\n",
      "        nan        nan        nan 0.67424242 0.67424242 0.67424242\n",
      " 0.67424242 0.67424242 0.67424242        nan        nan        nan\n",
      " 0.64141414 0.64141414 0.64141414 0.64141414 0.64141414 0.64141414\n",
      "        nan        nan        nan 0.67424242 0.67424242 0.67424242\n",
      " 0.67424242 0.67424242 0.67424242        nan        nan        nan\n",
      " 0.70454545 0.70454545 0.70454545 0.70454545 0.70454545 0.70454545\n",
      "        nan        nan        nan 0.61616162 0.61616162 0.61616162\n",
      " 0.61616162 0.61616162 0.61616162        nan        nan        nan\n",
      " 0.67424242 0.67424242 0.67424242 0.67424242 0.67424242 0.67424242\n",
      "        nan        nan        nan 0.70454545 0.70454545 0.70454545\n",
      " 0.70454545 0.70454545 0.70454545        nan        nan        nan\n",
      " 0.64393939 0.64393939 0.64393939 0.64393939 0.64393939 0.64393939\n",
      "        nan        nan        nan 0.7020202  0.7020202  0.7020202\n",
      " 0.7020202  0.7020202  0.7020202         nan        nan        nan\n",
      " 0.67424242 0.67424242 0.67424242 0.67424242 0.67424242 0.67424242\n",
      "        nan        nan        nan 0.58333333 0.58333333 0.58333333\n",
      " 0.58333333 0.58333333 0.58333333        nan        nan        nan\n",
      " 0.67171717 0.67171717 0.67171717 0.67171717 0.67171717 0.67171717\n",
      "        nan        nan        nan 0.67424242 0.67424242 0.67424242\n",
      " 0.67424242 0.67424242 0.67424242        nan        nan        nan\n",
      " 0.64393939 0.64393939 0.64393939 0.64393939 0.64393939 0.64393939\n",
      "        nan        nan        nan 0.64393939 0.64393939 0.64393939\n",
      " 0.64393939 0.64393939 0.64393939        nan        nan        nan\n",
      " 0.67424242 0.67424242 0.67424242 0.67424242 0.67424242 0.67424242\n",
      "        nan        nan        nan 0.61363636 0.61363636 0.61363636\n",
      " 0.61363636 0.61363636 0.61363636        nan        nan        nan\n",
      " 0.64393939 0.64393939 0.64393939 0.64393939 0.64393939 0.64393939\n",
      "        nan        nan        nan 0.67424242 0.67424242 0.67424242\n",
      " 0.67424242 0.67424242 0.67424242        nan        nan        nan\n",
      " 0.61363636 0.61363636 0.61363636 0.61363636 0.61363636 0.61363636\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib\n",
    "\n",
    "# 데이터 불러오기\n",
    "os.chdir('C:/Users/USER/Desktop/핵심역량 프로젝트/데이터/라벨링 데이터')\n",
    "\n",
    "data1 = pd.read_csv('0726_masking_labeling_data_0.csv')\n",
    "data2 = pd.read_csv('0726_masking_labeling_data_1.csv')\n",
    "\n",
    "data1 = data1.rename(columns={'text_morphed':'text_morphed_'})\n",
    "data2 = data2.rename(columns={'text_morphed':'text_morphed_'})\n",
    "\n",
    "data1 = data1.rename(columns={'저격성 민원':'저격성민원_'})\n",
    "data2 = data2.rename(columns={'저격성 민원':'저격성민원_'})\n",
    "\n",
    "selected_columns1 = ['text_morphed_', 'aggr', '욕설_모욕', '비꼼_시비', '성희롱', '요지불명', '저격성민원_']\n",
    "data1 = data1[selected_columns1]\n",
    "data2 = data2[selected_columns1]\n",
    "data1 = data1[:366]\n",
    "data2 = data2[data2.aggr == 1]\n",
    "\n",
    "data3 = pd.concat([data1, data2])\n",
    "# 텍스트와 라벨 분리\n",
    "data_contents = data3['text_morphed_']\n",
    "data_labeling = data3['aggr']\n",
    "\n",
    "# 데이터 분할\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_contents, data_labeling, stratify=data_labeling, test_size=0.2, random_state=42)\n",
    "\n",
    "# 파이프라인 정의\n",
    "pipelines = {\n",
    "\n",
    "    'extra_trees': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('et', ExtraTreesClassifier())\n",
    "    ]),\n",
    "\n",
    "    'ridge_classifier': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('ridge', RidgeClassifier())\n",
    "    ]),\n",
    "\n",
    "    'logistic_regression': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('lr', LogisticRegression())\n",
    "    ]),\n",
    "\n",
    "    'naive_bayes': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('nb', MultinomialNB())\n",
    "    ]),\n",
    "\n",
    "    'svm': Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('svm', SVC())\n",
    "    ]),\n",
    "\n",
    "\n",
    "    'hard_model' : Pipeline([\n",
    "        ('vect', TfidfVectorizer()),\n",
    "        ('hard_model',VotingClassifier([('LR',LogisticRegression()),('ridge',RidgeClassifier()),('svm',SVC())],voting='hard'))\n",
    "\n",
    "    ])\n",
    "    \n",
    "\n",
    "}\n",
    "\n",
    "# 모델 훈련 및 평가\n",
    "for model_name, pipeline in pipelines.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # 텍스트 데이터를 TF-IDF 벡터로 변환\n",
    "    X_train_tfidf = pipeline.named_steps['vect'].fit_transform(X_train)\n",
    "    X_test_tfidf = pipeline.named_steps['vect'].transform(X_test)\n",
    "    \n",
    "    # 차원 출력\n",
    "    print(f\"{model_name} - X_train shape: {X_train_tfidf.shape}\")\n",
    "    print(f\"{model_name} - X_test shape: {X_test_tfidf.shape}\")\n",
    "    \n",
    "    # 모델 훈련\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # 교차검증 점수 계산\n",
    "    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    \n",
    "    # 성능 출력\n",
    "    train_score = pipeline.score(X_train, y_train)\n",
    "    test_score = pipeline.score(X_test, y_test)\n",
    "    print(f\"{model_name} Train set score: {train_score:.4f}\")\n",
    "    print(f\"{model_name} Test set score: {test_score:.4f}\")\n",
    "    print(f\"{model_name} Cross-validation scores: {cv_scores}\")\n",
    "    print(f\"{model_name} Cross-validation mean score: {cv_scores.mean():.4f}\\n\")\n",
    "    \n",
    "    # 모델 저장\n",
    "    model_save_path = os.path.join('C:/Users/USER/Desktop/핵심역량 프로젝트/데이터/모델/', f'욕설_모욕_{model_name}_tfidf_nonemasking_model.pkl')\n",
    "    joblib.dump(pipeline, model_save_path)\n",
    "\n",
    "print(\"All models have been trained and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      안녕 하 관리자 `지역` 문화센터 인근 학교 재직 교사 `지역` 문화센터 근방 신호...\n",
       "1      안녕 하 `지역` 아이 주민 에 인도 파손 되 넘어지 경험 있 인도 파손 부분 인도...\n",
       "2      `지역` `지역` `지역` 차선 도로 파손 되 매우 크 불편 겪 사진 첨부 지하철 ...\n",
       "3      `지역` 교차로 비보 호 좌회전 신호 있 좌회전 신호일 때 좌회전 도로 횡단보도 신...\n",
       "4      안녕 하 코로나 도둑 맞 같 현실 모든 가족 너무 화 세상에 있 답답 일단 국민 신...\n",
       "                             ...                        \n",
       "192    `지역` 빌 쓰레기 처리 대하 건의 사람 알 빌라 주민 만나 옮기 주시 하 궁 나 ...\n",
       "193    추석연 휴 친정 이틀 `지역` 빌라 차이 아직 덥 때 문 열 미치 알 사람 버리 쓰...\n",
       "194                 지나 달 차례 문의 드리 아직 방지 턱 설치 안 되 있 지나 치이\n",
       "195    군수 건축 과장 안녕 하 지나 일요일 오전 군청 발주 하 `지역` 농공 단지 앞 하...\n",
       "196    군도 호선 미개 설 공 촉구 건 대하 부여군 건설과 도로계 대답 시원 보충 질문 존...\n",
       "Name: text_morphed_masked_, Length: 395, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_contents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
