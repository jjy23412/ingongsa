{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'number', 'title', 'title_morphed',\n",
       "       'title_essential_morphed', 'title_removeNN_essential_morphed',\n",
       "       'title_eomi_giho_essential_morphed',\n",
       "       'title_eomi_giho_essential_removeNN_morphed', 'title_morphed_masked',\n",
       "       'title_essential_morphed_masked',\n",
       "       'title_removeNN_essential_morphed_masked',\n",
       "       'title_eomi_giho_essential_morphed_masked',\n",
       "       'title_eomi_giho_essential_removeNN_morphed_masked', 'name', 'date',\n",
       "       'answer_state', 'contents', 'text_morphed', 'text_essential_morphed',\n",
       "       'text_removeNN_essential_morphed', 'text_eomi_giho_essential_morphed',\n",
       "       'text_eomi_giho_essential_removeNN_morphed', 'text_morphed_masked',\n",
       "       'text_essential_morphed_masked',\n",
       "       'text_removeNN_essential_morphed_masked',\n",
       "       'text_eomi_giho_essential_morphed_masked',\n",
       "       'text_eomi_giho_essential_removeNN_morphed_masked', 'has_attachment',\n",
       "       'answer_contents', 'registration_number', 'charge_name', 'charge',\n",
       "       'answer_date', 'title_and_contents', 'aggr', '욕설_모욕', '비꼼_시비', '성희롱',\n",
       "       '요지불명', '저격성 민원', '완전중복', '반복', '출처'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, RidgeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import joblib\n",
    "\n",
    "# 데이터 불러오기\n",
    "os.chdir('C:/Users/USER/Desktop/핵심역량 프로젝트/데이터/라벨링 데이터')\n",
    "\n",
    "data = pd.read_csv('0727_masking_labeling_data.csv')\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = data.columns[3:13]\n",
    "texts = data.columns[17:27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_aggr_training...\n",
      "\n",
      "Training extra_trees for aggr...\n",
      "extra_trees - X_train shape: (819, 11590)\n",
      "extra_trees - X_test shape: (205, 11590)\n",
      "extra_trees Train set score: 0.9988\n",
      "extra_trees Test set score: 0.8537\n",
      "extra_trees Cross-validation scores: [0.8902439  0.84756098 0.87195122 0.87195122 0.82822086]\n",
      "extra_trees Cross-validation mean score: 0.8620\n",
      "\n",
      "Training logistic_regression for aggr...\n",
      "logistic_regression - X_train shape: (819, 11590)\n",
      "logistic_regression - X_test shape: (205, 11590)\n",
      "logistic_regression Train set score: 0.9731\n",
      "logistic_regression Test set score: 0.8927\n",
      "logistic_regression Cross-validation scores: [0.86585366 0.85365854 0.86585366 0.8902439  0.8404908 ]\n",
      "logistic_regression Cross-validation mean score: 0.8632\n",
      "\n",
      "Training naive_bayes for aggr...\n",
      "naive_bayes - X_train shape: (819, 11590)\n",
      "naive_bayes - X_test shape: (205, 11590)\n",
      "naive_bayes Train set score: 0.9634\n",
      "naive_bayes Test set score: 0.8000\n",
      "naive_bayes Cross-validation scores: [0.82317073 0.77439024 0.76219512 0.77439024 0.76687117]\n",
      "naive_bayes Cross-validation mean score: 0.7802\n",
      "\n",
      "Training svm for aggr...\n",
      "svm - X_train shape: (819, 11590)\n",
      "svm - X_test shape: (205, 11590)\n",
      "svm Train set score: 0.9963\n",
      "svm Test set score: 0.9122\n",
      "svm Cross-validation scores: [0.8597561  0.88414634 0.86585366 0.89634146 0.8404908 ]\n",
      "svm Cross-validation mean score: 0.8693\n",
      "\n",
      "Training hard_model for aggr...\n",
      "hard_model - X_train shape: (819, 11590)\n",
      "hard_model - X_test shape: (205, 11590)\n",
      "hard_model Train set score: 0.9927\n",
      "hard_model Test set score: 0.8976\n",
      "hard_model Cross-validation scores: [0.87195122 0.87195122 0.87804878 0.8902439  0.83435583]\n",
      "hard_model Cross-validation mean score: 0.8693\n",
      "\n",
      "Training soft_model for aggr...\n",
      "soft_model - X_train shape: (819, 11590)\n",
      "soft_model - X_test shape: (205, 11590)\n",
      "soft_model Train set score: 0.9976\n",
      "soft_model Test set score: 0.8585\n",
      "soft_model Cross-validation scores: [0.88414634 0.85365854 0.88414634 0.88414634 0.85276074]\n",
      "soft_model Cross-validation mean score: 0.8718\n",
      "\n",
      "text_morphed_aggr_case_complete\n",
      "\n",
      "Training extra_trees for aggr...\n",
      "extra_trees - X_train shape: (819, 10326)\n",
      "extra_trees - X_test shape: (205, 10326)\n",
      "extra_trees Train set score: 0.9988\n",
      "extra_trees Test set score: 0.8390\n",
      "extra_trees Cross-validation scores: [0.84756098 0.81097561 0.86585366 0.84146341 0.87116564]\n",
      "extra_trees Cross-validation mean score: 0.8474\n",
      "\n",
      "Training logistic_regression for aggr...\n",
      "logistic_regression - X_train shape: (819, 10326)\n",
      "logistic_regression - X_test shape: (205, 10326)\n",
      "logistic_regression Train set score: 0.9768\n",
      "logistic_regression Test set score: 0.8537\n",
      "logistic_regression Cross-validation scores: [0.84756098 0.87195122 0.82926829 0.87804878 0.85889571]\n",
      "logistic_regression Cross-validation mean score: 0.8571\n",
      "\n",
      "Training naive_bayes for aggr...\n",
      "naive_bayes - X_train shape: (819, 10326)\n",
      "naive_bayes - X_test shape: (205, 10326)\n",
      "naive_bayes Train set score: 0.9719\n",
      "naive_bayes Test set score: 0.8195\n",
      "naive_bayes Cross-validation scores: [0.83536585 0.81707317 0.84756098 0.81097561 0.79754601]\n",
      "naive_bayes Cross-validation mean score: 0.8217\n",
      "\n",
      "Training svm for aggr...\n",
      "svm - X_train shape: (819, 10326)\n",
      "svm - X_test shape: (205, 10326)\n",
      "svm Train set score: 0.9939\n",
      "svm Test set score: 0.8585\n",
      "svm Cross-validation scores: [0.83536585 0.88414634 0.82926829 0.8597561  0.87730061]\n",
      "svm Cross-validation mean score: 0.8572\n",
      "\n",
      "Training hard_model for aggr...\n",
      "hard_model - X_train shape: (819, 10326)\n",
      "hard_model - X_test shape: (205, 10326)\n",
      "hard_model Train set score: 0.9902\n",
      "hard_model Test set score: 0.8585\n",
      "hard_model Cross-validation scores: [0.85365854 0.87804878 0.83536585 0.8902439  0.87116564]\n",
      "hard_model Cross-validation mean score: 0.8657\n",
      "\n",
      "Training soft_model for aggr...\n",
      "soft_model - X_train shape: (819, 10326)\n",
      "soft_model - X_test shape: (205, 10326)\n",
      "soft_model Train set score: 0.9976\n",
      "soft_model Test set score: 0.8537\n",
      "soft_model Cross-validation scores: [0.86585366 0.87195122 0.8597561  0.88414634 0.85889571]\n",
      "soft_model Cross-validation mean score: 0.8681\n",
      "\n",
      "text_essential_morphed_aggr_case_complete\n",
      "\n",
      "Training extra_trees for aggr...\n",
      "extra_trees - X_train shape: (819, 2925)\n",
      "extra_trees - X_test shape: (205, 2925)\n",
      "extra_trees Train set score: 0.9976\n",
      "extra_trees Test set score: 0.7805\n",
      "extra_trees Cross-validation scores: [0.77439024 0.74390244 0.79878049 0.79878049 0.7791411 ]\n",
      "extra_trees Cross-validation mean score: 0.7790\n",
      "\n",
      "Training logistic_regression for aggr...\n",
      "logistic_regression - X_train shape: (819, 2925)\n",
      "logistic_regression - X_test shape: (205, 2925)\n",
      "logistic_regression Train set score: 0.9377\n",
      "logistic_regression Test set score: 0.7756\n",
      "logistic_regression Cross-validation scores: [0.79268293 0.81097561 0.82317073 0.81097561 0.79754601]\n",
      "logistic_regression Cross-validation mean score: 0.8071\n",
      "\n",
      "Training naive_bayes for aggr...\n",
      "naive_bayes - X_train shape: (819, 2925)\n",
      "naive_bayes - X_test shape: (205, 2925)\n",
      "naive_bayes Train set score: 0.9145\n",
      "naive_bayes Test set score: 0.7707\n",
      "naive_bayes Cross-validation scores: [0.75       0.77439024 0.77439024 0.76219512 0.77300613]\n",
      "naive_bayes Cross-validation mean score: 0.7668\n",
      "\n",
      "Training svm for aggr...\n",
      "svm - X_train shape: (819, 2925)\n",
      "svm - X_test shape: (205, 2925)\n",
      "svm Train set score: 0.9939\n",
      "svm Test set score: 0.7854\n",
      "svm Cross-validation scores: [0.80487805 0.82317073 0.83536585 0.80487805 0.78527607]\n",
      "svm Cross-validation mean score: 0.8107\n",
      "\n",
      "Training hard_model for aggr...\n",
      "hard_model - X_train shape: (819, 2925)\n",
      "hard_model - X_test shape: (205, 2925)\n",
      "hard_model Train set score: 0.9853\n",
      "hard_model Test set score: 0.7805\n",
      "hard_model Cross-validation scores: [0.80487805 0.81707317 0.83536585 0.81707317 0.79754601]\n",
      "hard_model Cross-validation mean score: 0.8144\n",
      "\n",
      "Training soft_model for aggr...\n",
      "soft_model - X_train shape: (819, 2925)\n",
      "soft_model - X_test shape: (205, 2925)\n",
      "soft_model Train set score: 0.9951\n",
      "soft_model Test set score: 0.8000\n",
      "soft_model Cross-validation scores: [0.80487805 0.81097561 0.82317073 0.82317073 0.79141104]\n",
      "soft_model Cross-validation mean score: 0.8107\n",
      "\n",
      "text_removeNN_essential_morphed_aggr_case_complete\n",
      "\n",
      "Training extra_trees for aggr...\n",
      "extra_trees - X_train shape: (819, 10466)\n",
      "extra_trees - X_test shape: (205, 10466)\n",
      "extra_trees Train set score: 0.9988\n",
      "extra_trees Test set score: 0.8585\n",
      "extra_trees Cross-validation scores: [0.86585366 0.87195122 0.8902439  0.86585366 0.82208589]\n",
      "extra_trees Cross-validation mean score: 0.8632\n",
      "\n",
      "Training logistic_regression for aggr...\n",
      "logistic_regression - X_train shape: (819, 10466)\n",
      "logistic_regression - X_test shape: (205, 10466)\n",
      "logistic_regression Train set score: 0.9719\n",
      "logistic_regression Test set score: 0.8927\n",
      "logistic_regression Cross-validation scores: [0.87195122 0.88414634 0.85365854 0.88414634 0.86503067]\n",
      "logistic_regression Cross-validation mean score: 0.8718\n",
      "\n",
      "Training naive_bayes for aggr...\n",
      "naive_bayes - X_train shape: (819, 10466)\n",
      "naive_bayes - X_test shape: (205, 10466)\n",
      "naive_bayes Train set score: 0.9707\n",
      "naive_bayes Test set score: 0.8293\n",
      "naive_bayes Cross-validation scores: [0.82926829 0.82317073 0.82926829 0.81097561 0.80981595]\n",
      "naive_bayes Cross-validation mean score: 0.8205\n",
      "\n",
      "Training svm for aggr...\n",
      "svm - X_train shape: (819, 10466)\n",
      "svm - X_test shape: (205, 10466)\n",
      "svm Train set score: 0.9963\n",
      "svm Test set score: 0.8732\n",
      "svm Cross-validation scores: [0.87195122 0.88414634 0.84146341 0.8597561  0.84662577]\n",
      "svm Cross-validation mean score: 0.8608\n",
      "\n",
      "Training hard_model for aggr...\n",
      "hard_model - X_train shape: (819, 10466)\n",
      "hard_model - X_test shape: (205, 10466)\n",
      "hard_model Train set score: 0.9915\n",
      "hard_model Test set score: 0.8829\n",
      "hard_model Cross-validation scores: [0.8902439  0.8902439  0.8597561  0.88414634 0.85889571]\n",
      "hard_model Cross-validation mean score: 0.8767\n",
      "\n",
      "Training soft_model for aggr...\n",
      "soft_model - X_train shape: (819, 10466)\n",
      "soft_model - X_test shape: (205, 10466)\n",
      "soft_model Train set score: 0.9976\n",
      "soft_model Test set score: 0.8732\n",
      "soft_model Cross-validation scores: [0.89634146 0.86585366 0.8902439  0.87195122 0.85889571]\n",
      "soft_model Cross-validation mean score: 0.8767\n",
      "\n",
      "text_eomi_giho_essential_morphed_aggr_case_complete\n",
      "\n",
      "Training extra_trees for aggr...\n",
      "extra_trees - X_train shape: (819, 3066)\n",
      "extra_trees - X_test shape: (205, 3066)\n",
      "extra_trees Train set score: 0.9988\n",
      "extra_trees Test set score: 0.8244\n",
      "extra_trees Cross-validation scores: [0.80487805 0.79878049 0.81707317 0.81707317 0.82208589]\n",
      "extra_trees Cross-validation mean score: 0.8120\n",
      "\n",
      "Training logistic_regression for aggr...\n",
      "logistic_regression - X_train shape: (819, 3066)\n",
      "logistic_regression - X_test shape: (205, 3066)\n",
      "logistic_regression Train set score: 0.9377\n",
      "logistic_regression Test set score: 0.8000\n",
      "logistic_regression Cross-validation scores: [0.82317073 0.81707317 0.80487805 0.80487805 0.83435583]\n",
      "logistic_regression Cross-validation mean score: 0.8169\n",
      "\n",
      "Training naive_bayes for aggr...\n",
      "naive_bayes - X_train shape: (819, 3066)\n",
      "naive_bayes - X_test shape: (205, 3066)\n",
      "naive_bayes Train set score: 0.9145\n",
      "naive_bayes Test set score: 0.7902\n",
      "naive_bayes Cross-validation scores: [0.79268293 0.81097561 0.78658537 0.73780488 0.78527607]\n",
      "naive_bayes Cross-validation mean score: 0.7827\n",
      "\n",
      "Training svm for aggr...\n",
      "svm - X_train shape: (819, 3066)\n",
      "svm - X_test shape: (205, 3066)\n",
      "svm Train set score: 0.9927\n",
      "svm Test set score: 0.8146\n",
      "svm Cross-validation scores: [0.83536585 0.83536585 0.80487805 0.81707317 0.83435583]\n",
      "svm Cross-validation mean score: 0.8254\n",
      "\n",
      "Training hard_model for aggr...\n",
      "hard_model - X_train shape: (819, 3066)\n",
      "hard_model - X_test shape: (205, 3066)\n",
      "hard_model Train set score: 0.9853\n",
      "hard_model Test set score: 0.8146\n",
      "hard_model Cross-validation scores: [0.81707317 0.84146341 0.80487805 0.82926829 0.82822086]\n",
      "hard_model Cross-validation mean score: 0.8242\n",
      "\n",
      "Training soft_model for aggr...\n",
      "soft_model - X_train shape: (819, 3066)\n",
      "soft_model - X_test shape: (205, 3066)\n",
      "soft_model Train set score: 0.9951\n",
      "soft_model Test set score: 0.8244\n",
      "soft_model Cross-validation scores: [0.8597561  0.84146341 0.81707317 0.82926829 0.82208589]\n",
      "soft_model Cross-validation mean score: 0.8339\n",
      "\n",
      "text_eomi_giho_essential_removeNN_morphed_aggr_case_complete\n",
      "\n",
      "Training extra_trees for aggr...\n",
      "extra_trees - X_train shape: (819, 11061)\n",
      "extra_trees - X_test shape: (205, 11061)\n",
      "extra_trees Train set score: 0.9988\n",
      "extra_trees Test set score: 0.8585\n",
      "extra_trees Cross-validation scores: [0.87195122 0.81707317 0.87804878 0.8597561  0.82208589]\n",
      "extra_trees Cross-validation mean score: 0.8498\n",
      "\n",
      "Training logistic_regression for aggr...\n",
      "logistic_regression - X_train shape: (819, 11061)\n",
      "logistic_regression - X_test shape: (205, 11061)\n",
      "logistic_regression Train set score: 0.9683\n",
      "logistic_regression Test set score: 0.8732\n",
      "logistic_regression Cross-validation scores: [0.83536585 0.8597561  0.86585366 0.8597561  0.8404908 ]\n",
      "logistic_regression Cross-validation mean score: 0.8522\n",
      "\n",
      "Training naive_bayes for aggr...\n",
      "naive_bayes - X_train shape: (819, 11061)\n",
      "naive_bayes - X_test shape: (205, 11061)\n",
      "naive_bayes Train set score: 0.9512\n",
      "naive_bayes Test set score: 0.7902\n",
      "naive_bayes Cross-validation scores: [0.82926829 0.75       0.75609756 0.77439024 0.77300613]\n",
      "naive_bayes Cross-validation mean score: 0.7766\n",
      "\n",
      "Training svm for aggr...\n",
      "svm - X_train shape: (819, 11061)\n",
      "svm - X_test shape: (205, 11061)\n",
      "svm Train set score: 0.9951\n",
      "svm Test set score: 0.8878\n",
      "svm Cross-validation scores: [0.84756098 0.87195122 0.84756098 0.87195122 0.84662577]\n",
      "svm Cross-validation mean score: 0.8571\n",
      "\n",
      "Training hard_model for aggr...\n",
      "hard_model - X_train shape: (819, 11061)\n",
      "hard_model - X_test shape: (205, 11061)\n",
      "hard_model Train set score: 0.9915\n",
      "hard_model Test set score: 0.8878\n",
      "hard_model Cross-validation scores: [0.85365854 0.87195122 0.86585366 0.88414634 0.8404908 ]\n",
      "hard_model Cross-validation mean score: 0.8632\n",
      "\n",
      "Training soft_model for aggr...\n",
      "soft_model - X_train shape: (819, 11061)\n",
      "soft_model - X_test shape: (205, 11061)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "plt.style.use('default')\n",
    "\n",
    "font_location = 'C:/Windows/Fonts/malgun.ttf'\n",
    "font_name = fm.FontProperties(fname = font_location).get_name()\n",
    "matplotlib.rc('font',family = font_name)\n",
    "\n",
    "model_scores_save_path = 'C:/Users/USER/Desktop/핵심역량 프로젝트/데이터/모델/scores/ensemble/'\n",
    "visualization_save_path = 'C:/Users/USER/Desktop/핵심역량 프로젝트/데이터/모델/visualizations/'\n",
    "\n",
    "# Initialize the dictionary with 'scores' and 'cases_best_scores' keys\n",
    "All_model_scores = {}\n",
    "ensemble_models = {}\n",
    "best_models = {}\n",
    "\n",
    "target_columns = ['aggr', '욕설_모욕', '비꼼_시비', '반복', '요지불명', '저격성 민원']\n",
    "aggressive_columns = ['aggr', '욕설_모욕', '비꼼_시비', '요지불명']\n",
    "target_column_type = {'aggr': 'aggressive', '욕설_모욕': 'aggressive', '비꼼_시비': 'aggressive', '반복': 'neutral', '요지불명': 'aggressive', '저격성 민원': 'targeted'}\n",
    "\n",
    "for target_column in target_columns:\n",
    "\n",
    "    print(f'start_{target_column}_training...\\n')\n",
    "    All_model_scores[target_column] = {'scores': {}, 'cases_best_scores': {}}\n",
    "\n",
    "    for title, text in zip(titles, texts):\n",
    "        selected_columns = [title, text, 'aggr', '욕설_모욕', '비꼼_시비', '반복', '요지불명', '저격성 민원']\n",
    "        data1 = data[selected_columns][data[target_column] == 0]\n",
    "        data2 = data[selected_columns][data[target_column] == 1]\n",
    "        data1 = data1[300:300 + len(data2)]\n",
    "        \n",
    "        data3 = pd.concat([data1, data2])\n",
    "        data_contents = data3[title] + ' ' + data3[text]\n",
    "        data_labeling = data3[target_column]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_contents, data_labeling, stratify=data_labeling, test_size=0.2, random_state=42)\n",
    "\n",
    "        pipelines = {\n",
    "            'extra_trees': Pipeline([\n",
    "                ('vect', TfidfVectorizer()),\n",
    "                ('et', ExtraTreesClassifier())\n",
    "            ]),\n",
    "            'logistic_regression': Pipeline([\n",
    "                ('vect', TfidfVectorizer()),\n",
    "                ('lr', LogisticRegression())\n",
    "            ]),\n",
    "            'naive_bayes': Pipeline([\n",
    "                ('vect', TfidfVectorizer()),\n",
    "                ('nb', MultinomialNB())\n",
    "            ]),\n",
    "            'svm': Pipeline([\n",
    "                ('vect', TfidfVectorizer()),\n",
    "                ('svm', SVC(probability=True))\n",
    "            ]),\n",
    "            'hard_model': Pipeline([\n",
    "                ('vect', TfidfVectorizer()),\n",
    "                ('hard_model', VotingClassifier([('LR', LogisticRegression()), ('svm', SVC()), ('et', ExtraTreesClassifier()), ('nb', MultinomialNB())], voting='hard'))\n",
    "            ]),\n",
    "            'soft_model': Pipeline([\n",
    "                ('vect', TfidfVectorizer()),\n",
    "                ('soft_model', VotingClassifier([('LR', LogisticRegression()), ('svm', SVC(probability=True)), ('et', ExtraTreesClassifier()), ('nb', MultinomialNB())], voting='soft'))\n",
    "            ])\n",
    "        }\n",
    "\n",
    "        case_model_scores = {}\n",
    "        best_model_name = None\n",
    "        best_test_score = 0\n",
    "        best_cv_score = 0\n",
    "        best_confusion_matrix = None\n",
    "        best_classification_report = None\n",
    "        best_fp_rate = float('inf')\n",
    "        best_fn_rate = float('inf')\n",
    "\n",
    "        # 모델 훈련 및 평가\n",
    "        for model_name, pipeline in pipelines.items():\n",
    "            print(f\"Training {model_name} for {target_column}...\")\n",
    "\n",
    "            X_train_tfidf = pipeline.named_steps['vect'].fit_transform(X_train)\n",
    "            X_test_tfidf = pipeline.named_steps['vect'].transform(X_test)\n",
    "\n",
    "            print(f\"{model_name} - X_train shape: {X_train_tfidf.shape}\")\n",
    "            print(f\"{model_name} - X_test shape: {X_test_tfidf.shape}\")\n",
    "\n",
    "            pipeline.fit(X_train, y_train)\n",
    "\n",
    "            cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "            train_score = pipeline.score(X_train, y_train)\n",
    "            test_score = pipeline.score(X_test, y_test)\n",
    "            print(f\"{model_name} Train set score: {train_score:.4f}\")\n",
    "            print(f\"{model_name} Test set score: {test_score:.4f}\")\n",
    "            print(f\"{model_name} Cross-validation scores: {cv_scores}\")\n",
    "            print(f\"{model_name} Cross-validation mean score: {cv_scores.mean():.4f}\\n\")\n",
    "\n",
    "            if test_score >= 0.8:\n",
    "                y_pred = pipeline.predict(X_test)\n",
    "                cm = confusion_matrix(y_test, y_pred)\n",
    "                cr = classification_report(y_test, y_pred, output_dict=True)\n",
    "                fp_rate = cm[0][1] / (cm[0][1] + cm[0][0])  # 위양성 비율\n",
    "                fn_rate = cm[1][0] / (cm[1][0] + cm[1][1])  # 위음성 비율\n",
    "\n",
    "                case_model_scores[model_name] = {\n",
    "                    'test_score': test_score,\n",
    "                    'cv_scores': cv_scores.tolist(),  # Convert numpy array to list for JSON serialization\n",
    "                    'cv_mean_score': cv_scores.mean(),\n",
    "                    'confusion_matrix': cm.tolist(),  # Convert numpy array to list for JSON serialization\n",
    "                    'classification_report': cr,\n",
    "                    'fp_rate': fp_rate,\n",
    "                    'fn_rate': fn_rate\n",
    "                }\n",
    "\n",
    "                # 최고 점수 갱신\n",
    "                if test_score > best_test_score:\n",
    "                    best_test_score = test_score\n",
    "                    best_cv_score = cv_scores.mean()\n",
    "                    best_model_name = model_name\n",
    "                    best_confusion_matrix = cm\n",
    "                    best_classification_report = cr\n",
    "                    best_fp_rate = fp_rate\n",
    "                    best_fn_rate = fn_rate\n",
    "\n",
    "            model_save_path = os.path.join('C:/Users/USER/Desktop/핵심역량 프로젝트/데이터/모델/ensemble', f'{target_column}_{text}_{model_name}_tfidf_model.pkl')\n",
    "            joblib.dump(pipeline, model_save_path)\n",
    "\n",
    "        print(f'{text}_{target_column}_case_complete\\n')\n",
    "\n",
    "        # 각 케이스별 모델 점수 저장\n",
    "        All_model_scores[target_column]['scores'][text] = case_model_scores\n",
    "        # 최고 점수를 가진 모델 정보 저장\n",
    "        All_model_scores[target_column]['cases_best_scores'][text] = {\n",
    "            'model_name': best_model_name,\n",
    "            'test_score': best_test_score,\n",
    "            'cv_mean_score': best_cv_score,\n",
    "            'confusion_matrix': best_confusion_matrix.tolist() if best_confusion_matrix is not None else None,  # Convert numpy array to list for JSON serialization\n",
    "            'classification_report': best_classification_report,\n",
    "            'fp_rate': best_fp_rate,\n",
    "            'fn_rate': best_fn_rate\n",
    "        }\n",
    "\n",
    "    # 앙상블 모델 구축 및 저장\n",
    "    ensemble_pipelines = [\n",
    "        ('LR', LogisticRegression()),\n",
    "        ('svm', SVC(probability=True)),\n",
    "        ('et', ExtraTreesClassifier()),\n",
    "        ('nb', MultinomialNB())\n",
    "    ]\n",
    "\n",
    "    if target_column == '저격성 민원':\n",
    "        weights = [2 if name == 'LR' else 1 for name, _ in ensemble_pipelines]\n",
    "    elif target_column in aggressive_columns:\n",
    "        weights = [2 if name == 'et' else 1 for name, _ in ensemble_pipelines]\n",
    "    else:\n",
    "        weights = [1] * len(ensemble_pipelines)  # 중립의 경우 모든 모델에 동일 가중치\n",
    "\n",
    "    hard_ensemble_model = VotingClassifier(ensemble_pipelines, voting='hard')\n",
    "    soft_ensemble_model = VotingClassifier(ensemble_pipelines, voting='soft', weights=weights)\n",
    "\n",
    "    for ensemble_type, ensemble_model in [('hard', hard_ensemble_model), ('soft', soft_ensemble_model)]:\n",
    "        ensemble_pipeline = Pipeline([\n",
    "            ('vect', TfidfVectorizer()),\n",
    "            ('ensemble', ensemble_model)\n",
    "        ])\n",
    "\n",
    "        ensemble_pipeline.fit(X_train, y_train)\n",
    "        ensemble_test_score = ensemble_pipeline.score(X_test, y_test)\n",
    "        y_pred_ensemble = ensemble_pipeline.predict(X_test)\n",
    "        cm_ensemble = confusion_matrix(y_test, y_pred_ensemble)\n",
    "        cr_ensemble = classification_report(y_test, y_pred_ensemble, output_dict=True)\n",
    "        fp_rate_ensemble = cm_ensemble[0][1] / (cm_ensemble[0][1] + cm_ensemble[0][0])\n",
    "        fn_rate_ensemble = cm_ensemble[1][0] / (cm_ensemble[1][0] + cm_ensemble[1][1])\n",
    "\n",
    "        ensemble_models[f'{target_column}_{ensemble_type}'] = {\n",
    "            'test_score': ensemble_test_score,\n",
    "            'confusion_matrix': cm_ensemble.tolist(),\n",
    "            'classification_report': cr_ensemble,\n",
    "            'fp_rate': fp_rate_ensemble,\n",
    "            'fn_rate': fn_rate_ensemble\n",
    "        }\n",
    "\n",
    "        # Save ensemble model\n",
    "        ensemble_model_save_path = os.path.join('C:/Users/USER/Desktop/핵심역량 프로젝트/데이터/모델/ensemble', f'{target_column}_{ensemble_type}_ensemble_model.pkl')\n",
    "        joblib.dump(ensemble_pipeline, ensemble_model_save_path)\n",
    "\n",
    "        # Visualize confusion matrix\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        sns.heatmap(cm_ensemble, annot=True, fmt='g', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix for {target_column} - {ensemble_type}')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.savefig(os.path.join(visualization_save_path, f'{target_column}_{ensemble_type}_confusion_matrix.png'))\n",
    "        plt.close()\n",
    "\n",
    "    # 앙상블 결과를 반영한 베스트 모델 선택\n",
    "    if target_column in aggressive_columns:\n",
    "        best_fp_model_name = max(ensemble_models, key=lambda x: ensemble_models[x]['fp_rate'])\n",
    "        best_models[target_column] = {\n",
    "            'best_model_name': best_fp_model_name,\n",
    "            'best_test_score': ensemble_models[best_fp_model_name]['test_score'],\n",
    "            'best_cv_mean_score': best_cv_score,\n",
    "            'best_confusion_matrix': ensemble_models[best_fp_model_name]['confusion_matrix'],\n",
    "            'best_classification_report': ensemble_models[best_fp_model_name]['classification_report']\n",
    "        }\n",
    "    elif target_column == '저격성 민원':\n",
    "        best_fn_model_name = min(ensemble_models, key=lambda x: ensemble_models[x]['fn_rate'])\n",
    "        best_models[target_column] = {\n",
    "            'best_model_name': best_fn_model_name,\n",
    "            'best_test_score': ensemble_models[best_fn_model_name]['test_score'],\n",
    "            'best_cv_mean_score': best_cv_score,\n",
    "            'best_confusion_matrix': ensemble_models[best_fn_model_name]['confusion_matrix'],\n",
    "            'best_classification_report': ensemble_models[best_fn_model_name]['classification_report']\n",
    "        }\n",
    "    else:\n",
    "        best_models[target_column] = {\n",
    "            'best_model_name': best_model_name,\n",
    "            'best_test_score': best_test_score,\n",
    "            'best_cv_mean_score': best_cv_score,\n",
    "            'best_confusion_matrix': best_confusion_matrix.tolist() if best_confusion_matrix is not None else None,\n",
    "            'best_classification_report': best_classification_report\n",
    "        }\n",
    "\n",
    "# Save all model scores\n",
    "all_model_scores_save_path = os.path.join(model_scores_save_path, 'all_model_scores.json')\n",
    "with open(all_model_scores_save_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(All_model_scores, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Save best models\n",
    "best_models_save_path = os.path.join(model_scores_save_path, 'best_models.json')\n",
    "with open(best_models_save_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(best_models, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Save ensemble models\n",
    "ensemble_models_save_path = os.path.join(model_scores_save_path, 'ensemble_models.json')\n",
    "with open(ensemble_models_save_path, 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(ensemble_models, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"All models have been trained, evaluated, and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
